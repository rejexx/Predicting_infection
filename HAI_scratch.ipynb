{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "regulated-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fifteen-noise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3096, 77)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import data\n",
    "HAI_tidy = pd.read_csv('.\\data\\HAI_tidy_Wrangled.csv')\n",
    "HAI_tidy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "hourly-citizen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2219, 77)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop anything with NA in the predictor col\n",
    "HAI_tidy.dropna(subset=['HAI_2_SIR_Score'], inplace=True)\n",
    "HAI_tidy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "exciting-league",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2219 entries, 0 to 3095\n",
      "Data columns (total 75 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Facility ID                   2219 non-null   object \n",
      " 1   HAI_1_CILOWER                 1630 non-null   float64\n",
      " 2   HAI_1_CIUPPER                 1936 non-null   float64\n",
      " 3   HAI_1_DOPC                    2217 non-null   float64\n",
      " 4   HAI_1_ELIGCASES               2217 non-null   float64\n",
      " 5   HAI_1_NUMERATOR               2217 non-null   float64\n",
      " 6   HAI_1_SIR_Score               1936 non-null   float64\n",
      " 7   HAI_2_CILOWER                 1883 non-null   float64\n",
      " 8   HAI_2_CIUPPER                 2219 non-null   float64\n",
      " 9   HAI_2_DOPC                    2219 non-null   float64\n",
      " 10  HAI_2_ELIGCASES               2219 non-null   float64\n",
      " 11  HAI_2_NUMERATOR               2219 non-null   float64\n",
      " 12  HAI_2_SIR_Score               2219 non-null   float64\n",
      " 13  HAI_3_CILOWER                 1422 non-null   float64\n",
      " 14  HAI_3_CIUPPER                 1745 non-null   float64\n",
      " 15  HAI_3_DOPC                    2158 non-null   float64\n",
      " 16  HAI_3_ELIGCASES               2158 non-null   float64\n",
      " 17  HAI_3_NUMERATOR               2158 non-null   float64\n",
      " 18  HAI_3_SIR_Score               1745 non-null   float64\n",
      " 19  HAI_4_CILOWER                 610 non-null    float64\n",
      " 20  HAI_4_CIUPPER                 795 non-null    float64\n",
      " 21  HAI_4_DOPC                    2093 non-null   float64\n",
      " 22  HAI_4_ELIGCASES               2093 non-null   float64\n",
      " 23  HAI_4_NUMERATOR               2093 non-null   float64\n",
      " 24  HAI_4_SIR_Score               795 non-null    float64\n",
      " 25  HAI_5_CILOWER                 1440 non-null   float64\n",
      " 26  HAI_5_CIUPPER                 1689 non-null   float64\n",
      " 27  HAI_5_DOPC                    2198 non-null   float64\n",
      " 28  HAI_5_ELIGCASES               2198 non-null   float64\n",
      " 29  HAI_5_NUMERATOR               2198 non-null   float64\n",
      " 30  HAI_5_SIR_Score               1689 non-null   float64\n",
      " 31  HAI_6_CILOWER                 2137 non-null   float64\n",
      " 32  HAI_6_CIUPPER                 2185 non-null   float64\n",
      " 33  HAI_6_DOPC                    2204 non-null   float64\n",
      " 34  HAI_6_ELIGCASES               2204 non-null   float64\n",
      " 35  HAI_6_NUMERATOR               2204 non-null   float64\n",
      " 36  HAI_6_SIR_Score               2185 non-null   float64\n",
      " 37  HAI_1_SIR_ComparedToNational  1936 non-null   object \n",
      " 38  HAI_2_SIR_ComparedToNational  2219 non-null   object \n",
      " 39  HAI_3_SIR_ComparedToNational  1745 non-null   object \n",
      " 40  HAI_4_SIR_ComparedToNational  795 non-null    object \n",
      " 41  HAI_5_SIR_ComparedToNational  1689 non-null   object \n",
      " 42  HAI_6_SIR_ComparedToNational  2185 non-null   object \n",
      " 43  Facility Name                 2219 non-null   object \n",
      " 44  Address                       2219 non-null   object \n",
      " 45  City                          2219 non-null   object \n",
      " 46  State                         2219 non-null   object \n",
      " 47  ZIP Code                      2219 non-null   int64  \n",
      " 48  County Name                   2219 non-null   object \n",
      " 49  H_CLEAN_STAR_RATING           2175 non-null   float64\n",
      " 50  H_COMP_1_STAR_RATING          2175 non-null   float64\n",
      " 51  H_COMP_2_STAR_RATING          2175 non-null   float64\n",
      " 52  H_COMP_3_STAR_RATING          2175 non-null   float64\n",
      " 53  H_COMP_5_STAR_RATING          2175 non-null   float64\n",
      " 54  H_COMP_6_STAR_RATING          2175 non-null   float64\n",
      " 55  H_COMP_7_STAR_RATING          2175 non-null   float64\n",
      " 56  H_HSP_RATING_STAR_RATING      2175 non-null   float64\n",
      " 57  H_QUIET_STAR_RATING           2175 non-null   float64\n",
      " 58  H_RECMND_STAR_RATING          2175 non-null   float64\n",
      " 59  H_STAR_RATING                 2175 non-null   float64\n",
      " 60  H_CLEAN_LINEAR_SCORE          2175 non-null   float64\n",
      " 61  H_COMP_1_LINEAR_SCORE         2175 non-null   float64\n",
      " 62  H_COMP_2_LINEAR_SCORE         2175 non-null   float64\n",
      " 63  H_COMP_3_LINEAR_SCORE         2175 non-null   float64\n",
      " 64  H_COMP_5_LINEAR_SCORE         2175 non-null   float64\n",
      " 65  H_COMP_6_LINEAR_SCORE         2175 non-null   float64\n",
      " 66  H_COMP_7_LINEAR_SCORE         2175 non-null   float64\n",
      " 67  H_HSP_RATING_LINEAR_SCORE     2175 non-null   float64\n",
      " 68  H_QUIET_LINEAR_SCORE          2175 non-null   float64\n",
      " 69  H_RECMND_LINEAR_SCORE         2175 non-null   float64\n",
      " 70  SEP_1                         2065 non-null   float64\n",
      " 71  SEP_SH_3HR                    2060 non-null   float64\n",
      " 72  SEP_SH_6HR                    1574 non-null   float64\n",
      " 73  SEV_SEP_3HR                   2065 non-null   float64\n",
      " 74  SEV_SEP_6HR                   2057 non-null   float64\n",
      "dtypes: float64(62), int64(1), object(12)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#Drop info cols\n",
    "HAI_tidy.drop(['Phone Number', 'Location'], axis=\"columns\", inplace=True)\n",
    "HAI_tidy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "conceptual-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop upper and lower limts from HAI data\n",
    "HAI_tidy = HAI_tidy[HAI_tidy.columns.drop(HAI_tidy.filter(regex='CILOWER|CIUPPER').columns )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "generic-clinic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HAI_1_CILOWER', 'HAI_1_CIUPPER', 'HAI_1_DOPC', 'HAI_1_ELIGCASES',\n",
       "       'HAI_1_NUMERATOR', 'HAI_1_SIR_Score', 'HAI_2_CILOWER', 'HAI_2_CIUPPER',\n",
       "       'HAI_2_DOPC', 'HAI_2_ELIGCASES', 'HAI_2_NUMERATOR', 'HAI_2_SIR_Score',\n",
       "       'HAI_3_CILOWER', 'HAI_3_CIUPPER', 'HAI_3_DOPC', 'HAI_3_ELIGCASES',\n",
       "       'HAI_3_NUMERATOR', 'HAI_3_SIR_Score', 'HAI_4_CILOWER', 'HAI_4_CIUPPER',\n",
       "       'HAI_4_DOPC', 'HAI_4_ELIGCASES', 'HAI_4_NUMERATOR', 'HAI_4_SIR_Score',\n",
       "       'HAI_5_CILOWER', 'HAI_5_CIUPPER', 'HAI_5_DOPC', 'HAI_5_ELIGCASES',\n",
       "       'HAI_5_NUMERATOR', 'HAI_5_SIR_Score', 'HAI_6_CILOWER', 'HAI_6_CIUPPER',\n",
       "       'HAI_6_DOPC', 'HAI_6_ELIGCASES', 'HAI_6_NUMERATOR', 'HAI_6_SIR_Score',\n",
       "       'ZIP Code', 'H_CLEAN_STAR_RATING', 'H_COMP_1_STAR_RATING',\n",
       "       'H_COMP_2_STAR_RATING', 'H_COMP_3_STAR_RATING', 'H_COMP_5_STAR_RATING',\n",
       "       'H_COMP_6_STAR_RATING', 'H_COMP_7_STAR_RATING',\n",
       "       'H_HSP_RATING_STAR_RATING', 'H_QUIET_STAR_RATING',\n",
       "       'H_RECMND_STAR_RATING', 'H_STAR_RATING', 'H_CLEAN_LINEAR_SCORE',\n",
       "       'H_COMP_1_LINEAR_SCORE', 'H_COMP_2_LINEAR_SCORE',\n",
       "       'H_COMP_3_LINEAR_SCORE', 'H_COMP_5_LINEAR_SCORE',\n",
       "       'H_COMP_6_LINEAR_SCORE', 'H_COMP_7_LINEAR_SCORE',\n",
       "       'H_HSP_RATING_LINEAR_SCORE', 'H_QUIET_LINEAR_SCORE',\n",
       "       'H_RECMND_LINEAR_SCORE', 'SEP_1', 'SEP_SH_3HR', 'SEP_SH_6HR',\n",
       "       'SEV_SEP_3HR', 'SEV_SEP_6HR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "HAI_tidy = HAI_tidy.select_dtypes(include=numerics)\n",
    "HAI_tidy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "composite-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(HAI_tidy.drop(columns='HAI_2_SIR_Score'), \n",
    "                                                    HAI_tidy.HAI_2_SIR_Score, test_size=0.3, \n",
    "                                                    random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "wooden-reverse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7137044430135226"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code task 4#\n",
    "#Calculate the mean of `y_train`\n",
    "train_mean = y_train.mean()\n",
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "according-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the dummy regressor on the training data\n",
    "dumb_reg = DummyRegressor(strategy='mean')\n",
    "dumb_reg.fit(X_train, y_train)\n",
    "y_tr_pred = dumb_reg.predict(X_train)\n",
    "y_te_pred = train_mean * np.ones(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-prototype",
   "metadata": {},
   "source": [
    "Check the \"mean\" model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "heard-production",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -0.0010222673257951342)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "automated-picking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4233626112183842, 0.4496509574610026)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "wicked-throw",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.32846713157716884, 0.3541035498299305)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-oklahoma",
   "metadata": {},
   "source": [
    "Simplistic regression with imputation, taken from the guided capstone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "composite-trunk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HAI_1_CILOWER         0.2250\n",
       "HAI_1_CIUPPER         1.6555\n",
       "HAI_1_DOPC         4544.0000\n",
       "HAI_1_ELIGCASES       3.8595\n",
       "HAI_1_NUMERATOR       2.0000\n",
       "                     ...    \n",
       "SEP_1                59.0000\n",
       "SEP_SH_3HR           86.0000\n",
       "SEP_SH_6HR           70.0000\n",
       "SEV_SEP_3HR          81.0000\n",
       "SEV_SEP_6HR          90.0000\n",
       "Length: 62, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the values we'll use to fill in any missing values.  \n",
    "X_defaults_median = X_train.median()\n",
    "X_defaults_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dramatic-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call `X_train` and `X_test`'s `fillna()` method, passing `X_defaults_median` as the values to use\n",
    "#Assign the results to `X_tr` and `X_te`, respectively\n",
    "X_tr = X_train.fillna(X_defaults_median)\n",
    "X_te = X_test.fillna(X_defaults_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "consistent-spread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.59173428,  0.22088663, -0.36822895, -0.44907312, -0.37431823],\n",
       "       [-0.20804527,  0.63770751, -0.658202  , -0.61764412, -0.59876465],\n",
       "       [-0.20804527, -0.1497946 , -0.56681782, -0.56301718, -0.59876465],\n",
       "       [-0.51429246,  0.55715863, -0.54568913, -0.49137681, -0.37431823],\n",
       "       [-0.20804527, -1.34473325,  0.63127259,  0.27689495, -0.59876465]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call the StandardScaler`s fit method on `X_tr` to fit the scaler\n",
    "#then use it's `transform()` method to apply the scaling to both the train and test split\n",
    "#data (`X_tr` and `X_te`), naming the results `X_tr_scaled` and `X_te_scaled`, respectively\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr_scaled = scaler.transform(X_tr)\n",
    "X_te_scaled = scaler.transform(X_te)\n",
    "X_tr_scaled[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "continued-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression().fit(X_tr_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "union-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code task 11#\n",
    "#Call the `predict()` method of the model (`lm`) on both the (scaled) train and test data\n",
    "#Assign the predictions to `y_tr_pred` and `y_te_pred`, respectively\n",
    "y_tr_pred = lm.predict(X_tr_scaled)\n",
    "y_te_pred = lm.predict(X_te_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "demographic-florist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8846634838634866, 0.8589095100010494)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r^2 - train, test\n",
    "median_r2 = r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)\n",
    "median_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "stunning-stomach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13727833787715046, 0.15456243429613584)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code task 12#\n",
    "#Now calculate the mean absolute error scores using `sklearn`'s `mean_absolute_error` function\n",
    "# as we did above for R^2\n",
    "# MAE - train, test\n",
    "median_mae = mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)\n",
    "median_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "historic-packing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19463878, 0.22340462])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code task 13#\n",
    "#And also do the same using `sklearn`'s `mean_squared_error`\n",
    "# MSE - train, test\n",
    "median_mse = mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred)\n",
    "np.sqrt(median_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
