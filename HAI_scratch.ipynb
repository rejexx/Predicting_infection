{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "regulated-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fifteen-noise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3096, 77)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import data\n",
    "HAI_tidy = pd.read_csv('.\\data\\HAI_tidy_Wrangled.csv')\n",
    "HAI_tidy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "hourly-citizen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2219, 77)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop anything with NA in the predictor col\n",
    "HAI_tidy.dropna(subset=['HAI_2_SIR_Score'], inplace=True)\n",
    "HAI_tidy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "exciting-league",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2219 entries, 0 to 3095\n",
      "Data columns (total 75 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Facility ID                   2219 non-null   object \n",
      " 1   HAI_1_CILOWER                 1630 non-null   float64\n",
      " 2   HAI_1_CIUPPER                 1936 non-null   float64\n",
      " 3   HAI_1_DOPC                    2217 non-null   float64\n",
      " 4   HAI_1_ELIGCASES               2217 non-null   float64\n",
      " 5   HAI_1_NUMERATOR               2217 non-null   float64\n",
      " 6   HAI_1_SIR_Score               1936 non-null   float64\n",
      " 7   HAI_2_CILOWER                 1883 non-null   float64\n",
      " 8   HAI_2_CIUPPER                 2219 non-null   float64\n",
      " 9   HAI_2_DOPC                    2219 non-null   float64\n",
      " 10  HAI_2_ELIGCASES               2219 non-null   float64\n",
      " 11  HAI_2_NUMERATOR               2219 non-null   float64\n",
      " 12  HAI_2_SIR_Score               2219 non-null   float64\n",
      " 13  HAI_3_CILOWER                 1422 non-null   float64\n",
      " 14  HAI_3_CIUPPER                 1745 non-null   float64\n",
      " 15  HAI_3_DOPC                    2158 non-null   float64\n",
      " 16  HAI_3_ELIGCASES               2158 non-null   float64\n",
      " 17  HAI_3_NUMERATOR               2158 non-null   float64\n",
      " 18  HAI_3_SIR_Score               1745 non-null   float64\n",
      " 19  HAI_4_CILOWER                 610 non-null    float64\n",
      " 20  HAI_4_CIUPPER                 795 non-null    float64\n",
      " 21  HAI_4_DOPC                    2093 non-null   float64\n",
      " 22  HAI_4_ELIGCASES               2093 non-null   float64\n",
      " 23  HAI_4_NUMERATOR               2093 non-null   float64\n",
      " 24  HAI_4_SIR_Score               795 non-null    float64\n",
      " 25  HAI_5_CILOWER                 1440 non-null   float64\n",
      " 26  HAI_5_CIUPPER                 1689 non-null   float64\n",
      " 27  HAI_5_DOPC                    2198 non-null   float64\n",
      " 28  HAI_5_ELIGCASES               2198 non-null   float64\n",
      " 29  HAI_5_NUMERATOR               2198 non-null   float64\n",
      " 30  HAI_5_SIR_Score               1689 non-null   float64\n",
      " 31  HAI_6_CILOWER                 2137 non-null   float64\n",
      " 32  HAI_6_CIUPPER                 2185 non-null   float64\n",
      " 33  HAI_6_DOPC                    2204 non-null   float64\n",
      " 34  HAI_6_ELIGCASES               2204 non-null   float64\n",
      " 35  HAI_6_NUMERATOR               2204 non-null   float64\n",
      " 36  HAI_6_SIR_Score               2185 non-null   float64\n",
      " 37  HAI_1_SIR_ComparedToNational  1936 non-null   object \n",
      " 38  HAI_2_SIR_ComparedToNational  2219 non-null   object \n",
      " 39  HAI_3_SIR_ComparedToNational  1745 non-null   object \n",
      " 40  HAI_4_SIR_ComparedToNational  795 non-null    object \n",
      " 41  HAI_5_SIR_ComparedToNational  1689 non-null   object \n",
      " 42  HAI_6_SIR_ComparedToNational  2185 non-null   object \n",
      " 43  Facility Name                 2219 non-null   object \n",
      " 44  Address                       2219 non-null   object \n",
      " 45  City                          2219 non-null   object \n",
      " 46  State                         2219 non-null   object \n",
      " 47  ZIP Code                      2219 non-null   int64  \n",
      " 48  County Name                   2219 non-null   object \n",
      " 49  H_CLEAN_STAR_RATING           2175 non-null   float64\n",
      " 50  H_COMP_1_STAR_RATING          2175 non-null   float64\n",
      " 51  H_COMP_2_STAR_RATING          2175 non-null   float64\n",
      " 52  H_COMP_3_STAR_RATING          2175 non-null   float64\n",
      " 53  H_COMP_5_STAR_RATING          2175 non-null   float64\n",
      " 54  H_COMP_6_STAR_RATING          2175 non-null   float64\n",
      " 55  H_COMP_7_STAR_RATING          2175 non-null   float64\n",
      " 56  H_HSP_RATING_STAR_RATING      2175 non-null   float64\n",
      " 57  H_QUIET_STAR_RATING           2175 non-null   float64\n",
      " 58  H_RECMND_STAR_RATING          2175 non-null   float64\n",
      " 59  H_STAR_RATING                 2175 non-null   float64\n",
      " 60  H_CLEAN_LINEAR_SCORE          2175 non-null   float64\n",
      " 61  H_COMP_1_LINEAR_SCORE         2175 non-null   float64\n",
      " 62  H_COMP_2_LINEAR_SCORE         2175 non-null   float64\n",
      " 63  H_COMP_3_LINEAR_SCORE         2175 non-null   float64\n",
      " 64  H_COMP_5_LINEAR_SCORE         2175 non-null   float64\n",
      " 65  H_COMP_6_LINEAR_SCORE         2175 non-null   float64\n",
      " 66  H_COMP_7_LINEAR_SCORE         2175 non-null   float64\n",
      " 67  H_HSP_RATING_LINEAR_SCORE     2175 non-null   float64\n",
      " 68  H_QUIET_LINEAR_SCORE          2175 non-null   float64\n",
      " 69  H_RECMND_LINEAR_SCORE         2175 non-null   float64\n",
      " 70  SEP_1                         2065 non-null   float64\n",
      " 71  SEP_SH_3HR                    2060 non-null   float64\n",
      " 72  SEP_SH_6HR                    1574 non-null   float64\n",
      " 73  SEV_SEP_3HR                   2065 non-null   float64\n",
      " 74  SEV_SEP_6HR                   2057 non-null   float64\n",
      "dtypes: float64(62), int64(1), object(12)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#Drop info cols\n",
    "HAI_tidy.drop(['Phone Number', 'Location'], axis=\"columns\", inplace=True)\n",
    "HAI_tidy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "conceptual-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop upper and lower limts from HAI data\n",
    "HAI_tidy = HAI_tidy[HAI_tidy.columns.drop(HAI_tidy.filter(regex='CILOWER|CIUPPER|DOPC|ELIG|NUMERATOR').columns )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "generic-clinic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HAI_1_SIR_Score', 'HAI_2_SIR_Score', 'HAI_3_SIR_Score',\n",
       "       'HAI_4_SIR_Score', 'HAI_5_SIR_Score', 'HAI_6_SIR_Score', 'ZIP Code',\n",
       "       'H_CLEAN_STAR_RATING', 'H_COMP_1_STAR_RATING', 'H_COMP_2_STAR_RATING',\n",
       "       'H_COMP_3_STAR_RATING', 'H_COMP_5_STAR_RATING', 'H_COMP_6_STAR_RATING',\n",
       "       'H_COMP_7_STAR_RATING', 'H_HSP_RATING_STAR_RATING',\n",
       "       'H_QUIET_STAR_RATING', 'H_RECMND_STAR_RATING', 'H_STAR_RATING',\n",
       "       'H_CLEAN_LINEAR_SCORE', 'H_COMP_1_LINEAR_SCORE',\n",
       "       'H_COMP_2_LINEAR_SCORE', 'H_COMP_3_LINEAR_SCORE',\n",
       "       'H_COMP_5_LINEAR_SCORE', 'H_COMP_6_LINEAR_SCORE',\n",
       "       'H_COMP_7_LINEAR_SCORE', 'H_HSP_RATING_LINEAR_SCORE',\n",
       "       'H_QUIET_LINEAR_SCORE', 'H_RECMND_LINEAR_SCORE', 'SEP_1', 'SEP_SH_3HR',\n",
       "       'SEP_SH_6HR', 'SEV_SEP_3HR', 'SEV_SEP_6HR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "HAI_tidy = HAI_tidy.select_dtypes(include=numerics)\n",
    "HAI_tidy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "composite-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(HAI_tidy.drop(columns='HAI_2_SIR_Score'), \n",
    "                                                    HAI_tidy.HAI_2_SIR_Score, test_size=0.3, \n",
    "                                                    random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "wooden-reverse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7137044430135226"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code task 4#\n",
    "#Calculate the mean of `y_train`\n",
    "train_mean = y_train.mean()\n",
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "according-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the dummy regressor on the training data\n",
    "dumb_reg = DummyRegressor(strategy='mean')\n",
    "dumb_reg.fit(X_train, y_train)\n",
    "y_tr_pred = dumb_reg.predict(X_train)\n",
    "y_te_pred = train_mean * np.ones(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-prototype",
   "metadata": {},
   "source": [
    "Check the \"mean\" model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "heard-production",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -0.0010222673257951342)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "automated-picking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4233626112183842, 0.4496509574610026)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "wicked-throw",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.32846713157716884, 0.3541035498299305)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-oklahoma",
   "metadata": {},
   "source": [
    "Simplistic regression with imputation, taken from the guided capstone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "composite-trunk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HAI_1_SIR_Score                  0.604\n",
       "HAI_3_SIR_Score                  0.709\n",
       "HAI_4_SIR_Score                  0.744\n",
       "HAI_5_SIR_Score                  0.740\n",
       "HAI_6_SIR_Score                  0.541\n",
       "ZIP Code                     46321.000\n",
       "H_CLEAN_STAR_RATING              3.000\n",
       "H_COMP_1_STAR_RATING             3.000\n",
       "H_COMP_2_STAR_RATING             3.000\n",
       "H_COMP_3_STAR_RATING             3.000\n",
       "H_COMP_5_STAR_RATING             3.000\n",
       "H_COMP_6_STAR_RATING             3.000\n",
       "H_COMP_7_STAR_RATING             3.000\n",
       "H_HSP_RATING_STAR_RATING         3.000\n",
       "H_QUIET_STAR_RATING              3.000\n",
       "H_RECMND_STAR_RATING             3.000\n",
       "H_STAR_RATING                    3.000\n",
       "H_CLEAN_LINEAR_SCORE            87.000\n",
       "H_COMP_1_LINEAR_SCORE           91.000\n",
       "H_COMP_2_LINEAR_SCORE           91.000\n",
       "H_COMP_3_LINEAR_SCORE           84.000\n",
       "H_COMP_5_LINEAR_SCORE           77.000\n",
       "H_COMP_6_LINEAR_SCORE           87.000\n",
       "H_COMP_7_LINEAR_SCORE           81.000\n",
       "H_HSP_RATING_LINEAR_SCORE       88.000\n",
       "H_QUIET_LINEAR_SCORE            81.000\n",
       "H_RECMND_LINEAR_SCORE           88.000\n",
       "SEP_1                           59.000\n",
       "SEP_SH_3HR                      86.000\n",
       "SEP_SH_6HR                      70.000\n",
       "SEV_SEP_3HR                     81.000\n",
       "SEV_SEP_6HR                     90.000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the values we'll use to fill in any missing values.  \n",
    "X_defaults_median = X_train.median()\n",
    "X_defaults_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dramatic-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call `X_train` and `X_test`'s `fillna()` method, passing `X_defaults_median` as the values to use\n",
    "#Assign the results to `X_tr` and `X_te`, respectively\n",
    "X_tr = X_train.fillna(X_defaults_median)\n",
    "X_te = X_test.fillna(X_defaults_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "consistent-spread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01526945,  1.1662046 ,  5.17420033, -0.60169024, -1.51594761],\n",
       "       [-1.15304008, -0.13973295, -0.13159546, -0.12010945, -0.82915817],\n",
       "       [-1.15304008, -0.13973295, -0.13159546,  0.06243923, -0.21372347],\n",
       "       [ 0.19909314, -0.21124453, -0.13159546, -0.50780806, -0.00560546],\n",
       "       [-1.15304008, -0.85825401, -0.13159546,  0.30062178,  0.88038265]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Call the StandardScaler`s fit method on `X_tr` to fit the scaler\n",
    "#then use it's `transform()` method to apply the scaling to both the train and test split\n",
    "#data (`X_tr` and `X_te`), naming the results `X_tr_scaled` and `X_te_scaled`, respectively\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr_scaled = scaler.transform(X_tr)\n",
    "X_te_scaled = scaler.transform(X_te)\n",
    "X_tr_scaled[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "continued-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression().fit(X_tr_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "union-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code task 11#\n",
    "#Call the `predict()` method of the model (`lm`) on both the (scaled) train and test data\n",
    "#Assign the predictions to `y_tr_pred` and `y_te_pred`, respectively\n",
    "y_tr_pred = lm.predict(X_tr_scaled)\n",
    "y_te_pred = lm.predict(X_te_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "demographic-florist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05512494245121191, 0.033650441239241324)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# r^2 - train, test\n",
    "median_r2 = r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)\n",
    "median_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "stunning-stomach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.408157569570065, 0.43970819457722626)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code task 12#\n",
    "#Now calculate the mean absolute error scores using `sklearn`'s `mean_absolute_error` function\n",
    "# as we did above for R^2\n",
    "# MAE - train, test\n",
    "median_mae = mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)\n",
    "median_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "historic-packing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55709999, 0.58466944])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code task 13#\n",
    "#And also do the same using `sklearn`'s `mean_squared_error`\n",
    "# MSE - train, test\n",
    "median_mse = mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred)\n",
    "np.sqrt(median_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
